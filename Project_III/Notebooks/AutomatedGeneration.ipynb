{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea72a1c4",
   "metadata": {},
   "source": [
    "## More automated approach to training architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ac73e",
   "metadata": {},
   "source": [
    "### Setting up the imports/project path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b493ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure notebook sees necessary paths\n",
    "import os, sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c5a14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pulpit\\DeepLearning\\DeepLearning\\Project_III\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from DataObjects.DataLoader import DataLoader\n",
    "from Architectures.DifussionModel import DiffusionModel\n",
    "from Trainers.DiffusionTrainer import TrainingConfig\n",
    "\n",
    "# Noise schedulers\n",
    "from diffusers import DDPMScheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "# Torch files\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Utils.utils import make_grid, evaluate\n",
    "\n",
    "from Architectures.DifussionModel import train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2266f260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Set up the correct device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277006f0",
   "metadata": {},
   "source": [
    "### Setup training objects for diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74917bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the config\n",
    "config = TrainingConfig().from_json(\"../configs/config5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4953db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data batches: 85\n",
      "Number of data batches: 68\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "Data3 = DataLoader(config.data_dir, batch_size=config.train_batch_size, shuffle=True, fraction = config.fraction, raw = True, dim_shape=config.image_size)\n",
    "print(f\"Number of data batches: {len(Data3)}\")\n",
    "\n",
    "Data2 = DataLoader(\"E:/Galery_BackupCopy/Codzienny autofotoportret/\", batch_size=config.train_batch_size, shuffle=True, fraction = 0.21, raw = True, dim_shape=config.image_size)\n",
    "print(f\"Number of data batches: {len(Data2)}\")\n",
    "\n",
    "Data = Data3 + Data2\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(Data, batch_size=config.train_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0792369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=config.num_train_timesteps, beta_start=config.beta_start, beta_end=config.beta_end, beta_schedule=config.beta_schedule, variance_type=config.variance_type)\n",
    "model = DiffusionModel.return_custom_arch(config)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b1c5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(len(Data) * config.num_epochs * config.train_batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pulpit\\DeepLearning\\DeepLearning\\Project_III\\venv\\Lib\\site-packages\\accelerate\\accelerator.py:498: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "Epoch 0:   0%|          | 0/152 [00:00<?, ?it/s]d:\\Pulpit\\DeepLearning\\DeepLearning\\Project_III\\venv\\Lib\\site-packages\\diffusers\\configuration_utils.py:141: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
      "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "Epoch 0: 100%|██████████| 152/152 [40:18<00:00, 15.91s/it, loss=0.0633, lr=3.04e-5, step=151]\n",
      "Epoch 1: 100%|██████████| 152/152 [41:10<00:00, 16.25s/it, loss=0.0394, lr=6.08e-5, step=303]\n",
      "Epoch 2: 100%|██████████| 152/152 [41:13<00:00, 16.27s/it, loss=0.0128, lr=9.12e-5, step=455]\n",
      "Epoch 3: 100%|██████████| 152/152 [41:19<00:00, 16.31s/it, loss=0.0118, lr=0.0001, step=607]\n",
      "Epoch 4: 100%|██████████| 152/152 [49:40<00:00, 19.61s/it, loss=0.00641, lr=0.0001, step=759]\n",
      "Epoch 5: 100%|██████████| 152/152 [49:04<00:00, 19.37s/it, loss=0.0216, lr=0.0001, step=911]\n",
      "Epoch 6: 100%|██████████| 152/152 [54:13<00:00, 21.41s/it, loss=0.0154, lr=0.0001, step=1063] \n",
      "Epoch 7: 100%|██████████| 152/152 [43:34<00:00, 17.20s/it, loss=0.0115, lr=0.0001, step=1215]\n",
      "Epoch 8: 100%|██████████| 152/152 [43:31<00:00, 17.18s/it, loss=0.0104, lr=0.0001, step=1367] \n",
      "Epoch 9: 100%|██████████| 152/152 [43:20<00:00, 17.11s/it, loss=0.00408, lr=0.0001, step=1519]\n",
      "Epoch 10: 100%|██████████| 152/152 [44:12<00:00, 17.45s/it, loss=0.0199, lr=0.0001, step=1671] \n",
      "Epoch 11: 100%|██████████| 152/152 [1:01:54<00:00, 24.44s/it, loss=0.00993, lr=0.0001, step=1823]\n",
      "Epoch 12: 100%|██████████| 152/152 [1:16:57<00:00, 30.38s/it, loss=0.0249, lr=0.0001, step=1975] \n",
      "Epoch 13: 100%|██████████| 152/152 [1:48:26<00:00, 42.80s/it, loss=0.00458, lr=0.0001, step=2127]\n",
      "Epoch 14: 100%|██████████| 152/152 [55:36<00:00, 21.95s/it, loss=0.0108, lr=9.99e-5, step=2279] \n",
      "Epoch 15: 100%|██████████| 152/152 [1:06:12<00:00, 26.14s/it, loss=0.0215, lr=9.99e-5, step=2431]\n",
      "Epoch 16: 100%|██████████| 152/152 [49:04<00:00, 19.37s/it, loss=0.0162, lr=9.99e-5, step=2583] \n",
      "Epoch 17: 100%|██████████| 152/152 [49:07<00:00, 19.39s/it, loss=0.0095, lr=9.99e-5, step=2735]\n",
      "Epoch 18: 100%|██████████| 152/152 [1:47:46<00:00, 42.54s/it, loss=0.00932, lr=9.99e-5, step=2887]   \n"
     ]
    }
   ],
   "source": [
    "## Launch the training\n",
    "from accelerate import notebook_launcher\n",
    "args = (config, model, noise_scheduler, optimizer, Data, lr_scheduler, device)\n",
    "\n",
    "notebook_launcher(train_loop, args, num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841dc0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Architectures.DifussionModel import generate\n",
    "# Generation!\n",
    "generate(config, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8218fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device).eval()\n",
    "noise_scheduler = noise_scheduler\n",
    "pipeline = DDPMPipeline(\n",
    "    unet=model,\n",
    "    scheduler=noise_scheduler,\n",
    ")\n",
    "pipeline.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a5e306",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
