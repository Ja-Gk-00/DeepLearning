{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:26:21.379463Z",
     "start_time": "2025-06-07T08:26:19.554176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from Architectures.ConvolutionalAutoEncoder import ConvAutoEncoder\n",
    "from DataObjects.DataLoader import DataLoader\n",
    "import os"
   ],
   "id": "c480a67a17243b8c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:26:21.495595Z",
     "start_time": "2025-06-07T08:26:21.481331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "a06729502a05d05c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:26:21.530464Z",
     "start_time": "2025-06-07T08:26:21.528353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the current directory of the script (DataObjects)\n",
    "current_script_dir = os.getcwd()\n",
    "\n",
    "# Go up one level to the project root\n",
    "project_root = os.path.dirname(current_script_dir)\n",
    "\n",
    "data_dir = os.path.join(project_root, 'data', 'downscaled')"
   ],
   "id": "deac0e8dd5fd78be",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:26:29.300916Z",
     "start_time": "2025-06-07T08:26:21.571406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "Data_cats = DataLoader(data_dir , batch_size=batch_size, shuffle=True)\n",
    "print(f\"Number of cat batches: {len(Data_cats)}\")\n",
    "Data_dogs = DataLoader(data_dir + '/dog/', batch_size=batch_size, shuffle=True)\n",
    "print(f\"Number of dog batches: {len(Data_dogs)}\")"
   ],
   "id": "806905b322c3b7d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cat batches: 933\n",
      "Number of dog batches: 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:26:34.483375Z",
     "start_time": "2025-06-07T08:26:29.308754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvAutoEncoder.from_pretrained(device)\n",
    "\n",
    "model.train_architecture(Data_cats, epochs)\n",
    "model.save_model(f\"../Saved_Models/cae_model.pt\")\n",
    "model.load_model(f\"../Saved_Models/cae_model.pt\", map_location=device)"
   ],
   "id": "39674a680202ceb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on device: cuda\n",
      "First conv layer device: cuda:0\n",
      "Model moved to device: cuda\n",
      "Model parameters on device: cuda:0\n",
      "Epoch [1/1], Batch [0/933], Loss: 0.7591\n",
      "Epoch [1/1], Batch [100/933], Loss: 0.0587\n",
      "Epoch [1/1], Batch [200/933], Loss: 0.0396\n",
      "Epoch [1/1], Batch [300/933], Loss: 0.0303\n",
      "Epoch [1/1], Batch [400/933], Loss: 0.0252\n",
      "Epoch [1/1], Batch [500/933], Loss: 0.0216\n",
      "Epoch [1/1], Batch [600/933], Loss: 0.0233\n",
      "Epoch [1/1], Batch [700/933], Loss: 0.0189\n",
      "Epoch [1/1], Batch [800/933], Loss: 0.0166\n",
      "Epoch [1/1], Batch [900/933], Loss: 0.0174\n",
      "Epoch [1/1] completed, Average Loss: 0.0349\n",
      "Model saved to ../Saved_Models/cae_model.pt\n",
      "Model loaded from ../Saved_Models/cae_model.pt and moved to cuda\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T08:26:54.324730Z",
     "start_time": "2025-06-07T08:26:54.306348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = model.generate(num_samples=4)\n",
    "for i, img in enumerate(samples):\n",
    "    torchvision.utils.save_image(img, f\"../Saved_Models/sample_{i}.png\")"
   ],
   "id": "7a6493b50b77c76f",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
