{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed3ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from DataObjects.DataLoader import DataLoader\n",
    "from Architectures.Statistical.GMM import GMMClassifier\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f48636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING SEED\n",
    "SEED = 42069    \n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e359207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set device to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94961eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e63d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {'bed': 0, 'bird': 1, 'cat': 2, 'dog': 3, 'down': 4, 'eight': 5, 'five': 6, 'four': 7, 'go': 8, 'happy': 9, 'house': 10, 'left': 11, 'marvin': 12, 'nine': 13, 'no': 14, 'off': 15, 'on': 16, 'one': 17, 'right': 18, 'seven': 19, 'sheila': 20, 'silence': 21, 'six': 22, 'stop': 23, 'three': 24, 'tree': 25, 'two': 26, 'up': 27, 'wow': 28, 'yes': 29, 'zero': 30}\n",
      "# training batches: 587\n",
      "# validation batches: 216\n",
      "# testing batches: 211\n"
     ]
    }
   ],
   "source": [
    "# prepare Data Loader files\n",
    "train_dir = DATA_PATH / Path(\"Fourier_transformed\", \"training\")\n",
    "val_dir = DATA_PATH / Path(\"Fourier_transformed\", \"validation\")\n",
    "test_dir = DATA_PATH / Path(\"Fourier_transformed\", \"testing\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    data_dir=train_dir,\n",
    "    data_type='fft',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    data_dir=val_dir,\n",
    "    data_type='fft',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    data_dir=test_dir,\n",
    "    data_type='fft',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Inspect class mapping and dataset size\n",
    "print(\"Classes:\", train_loader.class_to_idx)\n",
    "print(\"# training batches:\", len(train_loader))\n",
    "\n",
    "print(\"# validation batches:\", len(val_loader))\n",
    "\n",
    "print(\"# testing batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3afbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_model = GMMClassifier(\n",
    "    n_components=10,\n",
    "    covariance_type='full',\n",
    "    max_iter=105,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71344cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained GMMs for classes: [9, 13, 4, 8, 22, 5, 0, 18, 24, 11, 26, 15, 1, 14, 6, 27, 28, 2, 30, 3, 7, 16, 20, 25, 23, 29, 10, 19, 12, 17, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (10). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "gmm_model.train_architecture(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d062a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test summary:\n",
      "  loss: 183.1610\n",
      "  accuracy: 0.1682\n",
      "  precision: 0.1944\n",
      "  recall: 0.1693\n",
      "  f1: 0.1649\n"
     ]
    }
   ],
   "source": [
    "results = gmm_model.evaluate(test_loader * 0.2)\n",
    "print(\"Test summary:\")\n",
    "for metric, value in results['summary'].items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba9cb3",
   "metadata": {},
   "source": [
    "## More automated approach to running tests\n",
    "Running tests throgh an automated Experiment Object created through ExperimentFactory for easy and streamlined experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataObjects.Experiments import ExperimentFactory, GMMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa27c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set device to cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_exp = ExperimentFactory.create_experiment(\n",
    "    arch_name='gmm',\n",
    "    train_dir='Data/Fourier_transformed/training',\n",
    "    val_dir='Data/Fourier_transformed/validation',\n",
    "    test_dir='Data/Fourier_transformed/testing',\n",
    "    batch_size=64,\n",
    "    save_path = \"Saved_experimented_data/GMM_experiment.txt\",\n",
    "    model_kwargs={\n",
    "        'n_components': 4,\n",
    "        'covariance_type': 'full',\n",
    "        'max_iter': 100,\n",
    "        'random_state': 42\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c732cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5216896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & device\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "# Make sure your DataLoader, SimpleCNN, and train_CNN are already defined above this cell!\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cp u')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data paths (reuse your variables)\n",
    "DATA_PATH = Path(\"Data\")\n",
    "train_dir = str(DATA_PATH / \"Fourier_transformed\" / \"training\")\n",
    "val_dir   = str(DATA_PATH / \"Fourier_transformed\" / \"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ddeea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GMM(config, device):\n",
    "    model = GMMClassifier(\n",
    "        max_iter=30,\n",
    "        random_state=SEED,\n",
    "        n_components=config[\"n_components\"],\n",
    "        covariance_type=config[\"covariance_type\"],\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        data_dir=config[\"train_dir\"],\n",
    "        data_type='fft',\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        data_dir=config[\"val_dir\"],\n",
    "        data_type='fft',\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    model.train_architecture(train_loader=train_loader)\n",
    "    results = model.evaluate(val_loader)\n",
    "\n",
    "    final_loss = results[\"summary\"][\"loss\"]\n",
    "    final_acc  = results[\"summary\"][\"accuracy\"]\n",
    "    return final_loss, final_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8dd8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 1) sample hyperparameters\n",
    "    config = {\n",
    "        \"n_components\":         trial.suggest_categorical(\"n_components\", [2 ,6, 8, 12, 20]),\n",
    "        \"covariance_type\":     trial.suggest_categorical(\"covariance_type\", [\"full\", \"spherical\"]),\n",
    "        \"batch_size\": 32,\n",
    "        \"train_dir\":  train_dir,\n",
    "        \"val_dir\":    val_dir,\n",
    "    }\n",
    "\n",
    "    # initialize, train, and evaluate your model\n",
    "    final_loss, final_acc = train_GMM(config, device)\n",
    "    return final_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbebc0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 07:13:48,062] A new study created in memory with name: no-name-1a1db276-be64-4aad-92d8-20f4fd51f4a8\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (20). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained GMMs for classes: [20, 22, 14, 16, 1, 23, 25, 28, 11, 9, 13, 26, 30, 15, 8, 17, 24, 5, 0, 18, 7, 4, 6, 19, 12, 10, 3, 29, 27, 2, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 07:50:36,621] Trial 0 finished with value: 0.15219285506825442 and parameters: {'n_components': 20, 'covariance_type': 'full'}. Best is trial 0 with value: 0.15219285506825442.\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:268: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "[W 2025-04-29 07:50:51,725] Trial 1 failed with parameters: {'n_components': 6, 'covariance_type': 'spherical'} because of the following error: ValueError('Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\aaf6\\AppData\\Local\\Temp\\ipykernel_32376\\237227374.py\", line 12, in objective\n",
      "    final_loss, final_acc = train_GMM(config, device)\n",
      "  File \"C:\\Users\\aaf6\\AppData\\Local\\Temp\\ipykernel_32376\\4270822187.py\", line 22, in train_GMM\n",
      "    model.train_architecture(train_loader=train_loader)\n",
      "  File \"d:\\Pulpit\\DeepLearning\\DeepLearning\\Project_II\\Architectures\\Statistical\\GMM.py\", line 73, in train_architecture\n",
      "    gmm.fit(X)\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py\", line 181, in fit\n",
      "    self.fit_predict(X, y)\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py\", line 235, in fit_predict\n",
      "    self._initialize_parameters(X, random_state)\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py\", line 766, in _initialize_parameters\n",
      "    super()._initialize_parameters(X, random_state)\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py\", line 140, in _initialize_parameters\n",
      "    self._initialize(X, resp)\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py\", line 793, in _initialize\n",
      "    self.precisions_cholesky_ = _compute_precision_cholesky(\n",
      "  File \"c:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py\", line 346, in _compute_precision_cholesky\n",
      "    raise ValueError(estimate_precision_error_message)\n",
      "ValueError: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.\n",
      "[W 2025-04-29 07:50:51,727] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m      9\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     pruner\u001b[38;5;241m=\u001b[39mpruner\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# run 20 trials\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components\u001b[39m\u001b[38;5;124m\"\u001b[39m:         trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m2\u001b[39m ,\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m20\u001b[39m]),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:     trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcovariance_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspherical\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m:    val_dir,\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# initialize, train, and evaluate your model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m final_loss, final_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_GMM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_acc\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mtrain_GMM\u001b[1;34m(config, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     10\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     11\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     16\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     19\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     20\u001b[0m )\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_architecture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_loader)\n\u001b[0;32m     25\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Pulpit\\DeepLearning\\DeepLearning\\Project_II\\Architectures\\Statistical\\GMM.py:73\u001b[0m, in \u001b[0;36mGMMClassifier.train_architecture\u001b[1;34m(self, train_loader, epochs, val_loader, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(feats, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     67\u001b[0m     gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(\n\u001b[0;32m     68\u001b[0m         n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components,\n\u001b[0;32m     69\u001b[0m         covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_type,\n\u001b[0;32m     70\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m     71\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m     72\u001b[0m     )\n\u001b[1;32m---> 73\u001b[0m     \u001b[43mgmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m gmm\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained GMMs for classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:181\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:235\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_verbose_msg_init_beg(init)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_init:\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf \u001b[38;5;28;01mif\u001b[39;00m do_init \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlower_bound_\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:766\u001b[0m, in \u001b[0;36mGaussianMixture._initialize_parameters\u001b[1;34m(self, X, random_state)\u001b[0m\n\u001b[0;32m    760\u001b[0m compute_resp \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    764\u001b[0m )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_resp:\n\u001b[1;32m--> 766\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(X, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_base.py:140\u001b[0m, in \u001b[0;36mBaseMixture._initialize_parameters\u001b[1;34m(self, X, random_state)\u001b[0m\n\u001b[0;32m    133\u001b[0m     _, indices \u001b[38;5;241m=\u001b[39m kmeans_plusplus(\n\u001b[0;32m    134\u001b[0m         X,\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components,\n\u001b[0;32m    136\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m     resp[indices, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:793\u001b[0m, in \u001b[0;36mGaussianMixture._initialize\u001b[1;34m(self, X, resp)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariances_ \u001b[38;5;241m=\u001b[39m covariances\n\u001b[1;32m--> 793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_cholesky_ \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_precision_cholesky\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcovariances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_cholesky_ \u001b[38;5;241m=\u001b[39m _compute_precision_cholesky_from_precisions(\n\u001b[0;32m    798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecisions_init, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_type\n\u001b[0;32m    799\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:346\u001b[0m, in \u001b[0;36m_compute_precision_cholesky\u001b[1;34m(covariances, covariance_type)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39mless_equal(covariances, \u001b[38;5;241m0.0\u001b[39m)):\n\u001b[1;32m--> 346\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(estimate_precision_error_message)\n\u001b[0;32m    347\u001b[0m     precisions_chol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(covariances)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m precisions_chol\n",
      "\u001b[1;31mValueError\u001b[0m: Fitting the mixture model failed because some components have ill-defined empirical covariance (for instance caused by singleton or collapsed samples). Try to decrease the number of components, or increase reg_covar."
     ]
    }
   ],
   "source": [
    "# Cell 3: create & run the study\n",
    "pruner = SuccessiveHalvingPruner(\n",
    "    min_resource=1,          # minimum epochs before pruning\n",
    "    reduction_factor=2,      # cut half the trials each round\n",
    "    min_early_stopping_rate=1\n",
    ")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# run 10 trials\n",
    "study.optimize(objective, n_trials=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: examine results\n",
    "from optuna.trial import TrialState\n",
    "import pandas as pd\n",
    "\n",
    "# summary\n",
    "trials = study.trials\n",
    "n_complete = len([t for t in trials if t.state is TrialState.COMPLETE])\n",
    "n_pruned   = len([t for t in trials if t.state is TrialState.PRUNED])\n",
    "print(f\"Finished {len(trials)} trials: {n_complete} complete, {n_pruned} pruned\")\n",
    "\n",
    "# best trial\n",
    "best = study.best_trial\n",
    "print(f\"\\nBest accuracy: {best.value:.4f}\")\n",
    "print(\"Params:\")\n",
    "for k, v in best.params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# optional: dataframe of all trials\n",
    "df = study.trials_dataframe()\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
