{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T12:25:34.435547Z",
     "start_time": "2025-03-31T12:25:34.433080Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from Architectures.OptimalCNN import OptimalCNN\n",
    "from DataObjects import DataLoader\n",
    "import torch.optim as optim\n",
    "from Architectures.StochasticDepthCNN import StochasticDepthCNN\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Optional, Tuple"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:25:34.489525Z",
     "start_time": "2025-03-31T12:25:34.481581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                num_epochs: int = 10, lr: float = 0.001,\n",
    "                device: torch.device = None) -> None:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion: nn.Module = nn.CrossEntropyLoss()\n",
    "    optimizer: torch.optim.Optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss: float = 0.0\n",
    "        train_correct: int = 0\n",
    "        total_train: int = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels).item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = train_correct / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss: float = 0.0\n",
    "        val_correct: int = 0\n",
    "        total_val: int = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch.data.to(device)\n",
    "                labels = batch.labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels).item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = val_correct / total_val\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {avg_train_loss:.4f}, Train acc: {train_acc:.4f} | Val loss: {avg_val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             test_loader: Optional[DataLoader] = None,\n",
    "             device: Optional[torch.device] = None) -> Tuple[float, float]:\n",
    "\n",
    "    if test_loader is None:\n",
    "        test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "        test_loader = DataLoader(test_dir, batch_size=64, shuffle=True)\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_correct += torch.sum(preds == labels).item()\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / total_test\n",
    "    test_acc = test_correct / total_test\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    return avg_test_loss, test_acc"
   ],
   "id": "cc3308bed6385b92",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:25:34.893421Z",
     "start_time": "2025-03-31T12:25:34.523830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup directories and DataLoaders\n",
    "train_dir_10 = os.path.join(\"Data\", \"Data_few_10\", \"train\")\n",
    "train_dir_15 = os.path.join(\"Data\", \"Data_few_15\", \"train\")\n",
    "train_dir_20 = os.path.join(\"Data\", \"Data_few_20\", \"train\")\n",
    "\n",
    "val_dir_10 = os.path.join(\"Data\", \"Data_few_10\", \"valid\")\n",
    "val_dir_15 = os.path.join(\"Data\", \"Data_few_15\", \"valid\")\n",
    "val_dir_20 = os.path.join(\"Data\", \"Data_few_20\", \"valid\")\n",
    "\n",
    "test_dir_10 = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "test_dir_15 = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "test_dir_20 = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "\n",
    "train_loader_10 = DataLoader(train_dir_10, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "train_loader_15 = DataLoader(train_dir_15, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "train_loader_20 = DataLoader(train_dir_20, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "\n",
    "val_loader_10 = DataLoader(val_dir_10, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "val_loader_15 = DataLoader(val_dir_15, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "val_loader_20 = DataLoader(val_dir_20, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "\n",
    "test_loader_10 = DataLoader(test_dir_10, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "test_loader_15 = DataLoader(test_dir_15, batch_size=32, shuffle=True, max_per_class = 3000)\n",
    "test_loader_20 = DataLoader(test_dir_20, batch_size=32, shuffle=True, max_per_class = 3000)"
   ],
   "id": "a988f72267fc00d7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:26:21.812952Z",
     "start_time": "2025-03-31T12:25:34.899894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_10 = load_model(\"/home/piotr/PycharmProjects/dl_project1/DeepLearning/Project_I/Models_Pytorch_saved/model_Optimal_I_trained_saved.pth\")\n",
    "# Train the model\n",
    "train_model(model_10, train_loader_10, val_loader_10, num_epochs=10, lr=0.008)\n",
    "# Evaluate the model\n",
    "evaluate(model_10, test_loader_10)\n",
    "# Save the model\n",
    "save_model(model_10, \"Models_Pytorch_saved/model_few_10_trained_saved.pth\")"
   ],
   "id": "4cb991bdb6a8346e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /home/piotr/PycharmProjects/dl_project1/DeepLearning/Project_I/Models_Pytorch_saved/model_Optimal_I_trained_saved.pth\n",
      "Epoch 1/10 - Train loss: 1.1123, Train acc: 0.6459 | Val loss: 1.1845, Val acc: 0.6088\n",
      "Epoch 2/10 - Train loss: 0.6885, Train acc: 0.7650 | Val loss: 1.2272, Val acc: 0.6200\n",
      "Epoch 3/10 - Train loss: 0.4362, Train acc: 0.8513 | Val loss: 1.6295, Val acc: 0.5914\n",
      "Epoch 4/10 - Train loss: 0.2968, Train acc: 0.9027 | Val loss: 1.6904, Val acc: 0.5738\n",
      "Epoch 5/10 - Train loss: 0.2063, Train acc: 0.9290 | Val loss: 1.7008, Val acc: 0.6074\n",
      "Epoch 6/10 - Train loss: 0.1873, Train acc: 0.9357 | Val loss: 1.8893, Val acc: 0.5962\n",
      "Epoch 7/10 - Train loss: 0.1630, Train acc: 0.9456 | Val loss: 2.0453, Val acc: 0.5831\n",
      "Epoch 8/10 - Train loss: 0.1495, Train acc: 0.9502 | Val loss: 2.2173, Val acc: 0.5894\n",
      "Epoch 9/10 - Train loss: 0.1214, Train acc: 0.9591 | Val loss: 2.0586, Val acc: 0.5900\n",
      "Epoch 10/10 - Train loss: 0.1212, Train acc: 0.9590 | Val loss: 2.2459, Val acc: 0.5841\n",
      "Test Loss: 1.7817, Test Accuracy: 0.6595\n",
      "Model saved successfully at Models_Pytorch_saved/model_few_10_trained_saved.pth\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:27:25.846641Z",
     "start_time": "2025-03-31T12:26:21.818903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_15 = load_model(\"/home/piotr/PycharmProjects/dl_project1/DeepLearning/Project_I/Models_Pytorch_saved/model_Optimal_I_trained_saved.pth\")\n",
    "# Train the model\n",
    "train_model(model_15, train_loader_15, val_loader_15, num_epochs=10, lr=0.008)\n",
    "# Evaluate the model\n",
    "evaluate(model_15, test_loader_15)\n",
    "# Save the model\n",
    "save_model(model_15, \"Models_Pytorch_saved/model_few_15_trained_saved.pth\")"
   ],
   "id": "a4064fe10cbdfbe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /home/piotr/PycharmProjects/dl_project1/DeepLearning/Project_I/Models_Pytorch_saved/model_Optimal_I_trained_saved.pth\n",
      "Epoch 1/10 - Train loss: 1.0689, Train acc: 0.6601 | Val loss: 1.0879, Val acc: 0.6143\n",
      "Epoch 2/10 - Train loss: 0.7250, Train acc: 0.7548 | Val loss: 1.2834, Val acc: 0.6139\n",
      "Epoch 3/10 - Train loss: 0.4998, Train acc: 0.8269 | Val loss: 1.3639, Val acc: 0.6109\n",
      "Epoch 4/10 - Train loss: 0.3545, Train acc: 0.8746 | Val loss: 1.4921, Val acc: 0.6067\n",
      "Epoch 5/10 - Train loss: 0.2875, Train acc: 0.9006 | Val loss: 1.7295, Val acc: 0.5955\n",
      "Epoch 6/10 - Train loss: 0.2090, Train acc: 0.9313 | Val loss: 1.8322, Val acc: 0.5953\n",
      "Epoch 7/10 - Train loss: 0.1915, Train acc: 0.9341 | Val loss: 1.8612, Val acc: 0.5993\n",
      "Epoch 8/10 - Train loss: 0.1628, Train acc: 0.9456 | Val loss: 2.0281, Val acc: 0.6039\n",
      "Epoch 9/10 - Train loss: 0.1554, Train acc: 0.9473 | Val loss: 2.0280, Val acc: 0.5907\n",
      "Epoch 10/10 - Train loss: 0.1496, Train acc: 0.9492 | Val loss: 2.1680, Val acc: 0.6053\n",
      "Test Loss: 1.7962, Test Accuracy: 0.6743\n",
      "Model saved successfully at Models_Pytorch_saved/model_few_15_trained_saved.pth\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:28:48.231199Z",
     "start_time": "2025-03-31T12:27:25.861538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_20 = load_model(\"/home/piotr/PycharmProjects/dl_project1/DeepLearning/Project_I/Models_Pytorch_saved/model_Optimal_I_trained_saved.pth\")\n",
    "# Train the model\n",
    "train_model(model_20, train_loader_20, val_loader_20, num_epochs=10, lr=0.008)\n",
    "# Evaluate the model\n",
    "evaluate(model_20, test_loader_20)\n",
    "# Save the model\n",
    "save_model(model_20, \"Models_Pytorch_saved/model_few_20_trained_saved.pth\")"
   ],
   "id": "7ca327eaf2cca009",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from /home/piotr/PycharmProjects/dl_project1/DeepLearning/Project_I/Models_Pytorch_saved/model_Optimal_I_trained_saved.pth\n",
      "Epoch 1/10 - Train loss: 1.0709, Train acc: 0.6556 | Val loss: 1.0743, Val acc: 0.6254\n",
      "Epoch 2/10 - Train loss: 0.7660, Train acc: 0.7366 | Val loss: 1.1496, Val acc: 0.6184\n",
      "Epoch 3/10 - Train loss: 0.5609, Train acc: 0.8035 | Val loss: 1.3112, Val acc: 0.6174\n",
      "Epoch 4/10 - Train loss: 0.4104, Train acc: 0.8556 | Val loss: 1.3273, Val acc: 0.6092\n",
      "Epoch 5/10 - Train loss: 0.3117, Train acc: 0.8934 | Val loss: 1.6623, Val acc: 0.6180\n",
      "Epoch 6/10 - Train loss: 0.2418, Train acc: 0.9172 | Val loss: 1.7521, Val acc: 0.6158\n",
      "Epoch 7/10 - Train loss: 0.2107, Train acc: 0.9260 | Val loss: 1.9155, Val acc: 0.5843\n",
      "Epoch 8/10 - Train loss: 0.1913, Train acc: 0.9334 | Val loss: 1.8574, Val acc: 0.6093\n",
      "Epoch 9/10 - Train loss: 0.1659, Train acc: 0.9439 | Val loss: 2.0242, Val acc: 0.5984\n",
      "Epoch 10/10 - Train loss: 0.1602, Train acc: 0.9468 | Val loss: 2.0757, Val acc: 0.5989\n",
      "Test Loss: 1.6991, Test Accuracy: 0.6751\n",
      "Model saved successfully at Models_Pytorch_saved/model_few_20_trained_saved.pth\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
