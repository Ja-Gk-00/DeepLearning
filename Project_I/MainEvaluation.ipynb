{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3090f1",
   "metadata": {},
   "source": [
    "# Training and Evaluation for CINIC10 using SimpleCNN and OptimalCNN\n",
    "\n",
    "This notebook loads the converted dataset, trains the SimpleCNN model, and performs evaluation and inference on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440dd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from DataObjects import DataLoader\n",
    "from Architectures.SimpleCNN import SimpleCNN\n",
    "from Architectures.OptimalCNN import OptimalCNN\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from utils import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0945689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                num_epochs: int = 10, lr: float = 0.001,\n",
    "                device: torch.device = None) -> None:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion: nn.Module = nn.CrossEntropyLoss()\n",
    "    optimizer: torch.optim.Optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss: float = 0.0\n",
    "        train_correct: int = 0\n",
    "        total_train: int = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels).item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = train_correct / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss: float = 0.0\n",
    "        val_correct: int = 0\n",
    "        total_val: int = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch.data.to(device)\n",
    "                labels = batch.labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels).item()\n",
    "                total_val += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = val_correct / total_val\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {avg_train_loss:.4f}, Train acc: {train_acc:.4f} | Val loss: {avg_val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "def infer(model: nn.Module, data_loader: DataLoader,\n",
    "          device: torch.device = None) -> list:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    predictions: list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             test_loader: Optional[DataLoader] = None,\n",
    "             device: Optional[torch.device] = None) -> Tuple[float, float]:\n",
    "\n",
    "    if test_loader is None:\n",
    "        test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "        test_loader = DataLoader(test_dir, batch_size=64, shuffle=True)\n",
    "        \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_correct += torch.sum(preds == labels).item()\n",
    "            total_test += labels.size(0)\n",
    "    \n",
    "    avg_test_loss = test_loss / total_test\n",
    "    test_acc = test_correct / total_test\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    return avg_test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee232775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories and DataLoaders\n",
    "train_dir = os.path.join(\"Data\", \"Data_converted\", \"train\")\n",
    "val_dir = os.path.join(\"Data\", \"Data_converted\", \"valid\")\n",
    "\n",
    "train_loader = DataLoader(train_dir, batch_size=64, shuffle=True, max_per_class=150)\n",
    "val_loader = DataLoader(val_dir, batch_size=64, shuffle=False, max_per_class=150) \n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96dd00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 1.1707, Train acc: 0.5867 | Val loss: 2.4186, Val acc: 0.2927\n",
      "Epoch 2/10 - Train loss: 0.8279, Train acc: 0.7253 | Val loss: 2.6018, Val acc: 0.3093\n",
      "Epoch 3/10 - Train loss: 0.5913, Train acc: 0.8080 | Val loss: 3.0063, Val acc: 0.3160\n",
      "Epoch 4/10 - Train loss: 0.4302, Train acc: 0.8573 | Val loss: 3.2185, Val acc: 0.3240\n",
      "Epoch 5/10 - Train loss: 0.3442, Train acc: 0.8920 | Val loss: 3.5537, Val acc: 0.3320\n",
      "Epoch 6/10 - Train loss: 0.2194, Train acc: 0.9400 | Val loss: 3.8268, Val acc: 0.3293\n",
      "Epoch 7/10 - Train loss: 0.1430, Train acc: 0.9693 | Val loss: 4.4267, Val acc: 0.3273\n",
      "Epoch 8/10 - Train loss: 0.1244, Train acc: 0.9687 | Val loss: 4.5080, Val acc: 0.3320\n",
      "Epoch 9/10 - Train loss: 0.1471, Train acc: 0.9607 | Val loss: 4.5738, Val acc: 0.3327\n",
      "Epoch 10/10 - Train loss: 0.2647, Train acc: 0.9227 | Val loss: 4.4066, Val acc: 0.3353\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189aca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.6793, Test Accuracy: 0.2764\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "test_loader = DataLoader(test_dir, batch_size=64, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch.data.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = test_correct / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e5fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training\n",
    "train_loader_full = DataLoader(train_dir, batch_size=64, shuffle=True)\n",
    "val_loader_full = DataLoader(val_dir, batch_size=64, shuffle=False) \n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = SimpleCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159fc1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 0.4291, Train acc: 0.8567 | Val loss: 3.3108, Val acc: 0.3347\n",
      "Epoch 2/10 - Train loss: 0.2400, Train acc: 0.9373 | Val loss: 3.4594, Val acc: 0.3313\n",
      "Epoch 3/10 - Train loss: 0.1584, Train acc: 0.9600 | Val loss: 3.8230, Val acc: 0.3373\n",
      "Epoch 4/10 - Train loss: 0.1177, Train acc: 0.9707 | Val loss: 4.3002, Val acc: 0.3387\n",
      "Epoch 5/10 - Train loss: 0.0707, Train acc: 0.9880 | Val loss: 4.4719, Val acc: 0.3520\n",
      "Epoch 6/10 - Train loss: 0.0504, Train acc: 0.9920 | Val loss: 4.7958, Val acc: 0.3433\n",
      "Epoch 7/10 - Train loss: 0.0460, Train acc: 0.9900 | Val loss: 5.1337, Val acc: 0.3320\n",
      "Epoch 8/10 - Train loss: 0.0937, Train acc: 0.9740 | Val loss: 5.1910, Val acc: 0.3100\n",
      "Epoch 9/10 - Train loss: 0.1296, Train acc: 0.9627 | Val loss: 5.4133, Val acc: 0.3193\n",
      "Epoch 10/10 - Train loss: 0.1153, Train acc: 0.9673 | Val loss: 5.2266, Val acc: 0.3307\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model_2, train_loader, val_loader, num_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb95a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.6793, Test Accuracy: 0.2764\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_2.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch.data.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = test_correct / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a23077da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different architecture\n",
    "model_Optimal = OptimalCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "154842b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 1.3769, Train acc: 0.5038 | Val loss: 1.1631, Val acc: 0.5820\n",
      "Epoch 2/10 - Train loss: 1.0768, Train acc: 0.6156 | Val loss: 1.1000, Val acc: 0.6120\n",
      "Epoch 3/10 - Train loss: 0.9368, Train acc: 0.6665 | Val loss: 0.9222, Val acc: 0.6721\n",
      "Epoch 4/10 - Train loss: 0.8269, Train acc: 0.7076 | Val loss: 0.9199, Val acc: 0.6748\n",
      "Epoch 5/10 - Train loss: 0.7204, Train acc: 0.7444 | Val loss: 0.8629, Val acc: 0.6960\n",
      "Epoch 6/10 - Train loss: 0.6109, Train acc: 0.7819 | Val loss: 0.8730, Val acc: 0.7029\n",
      "Epoch 7/10 - Train loss: 0.5006, Train acc: 0.8212 | Val loss: 0.9081, Val acc: 0.7003\n",
      "Epoch 8/10 - Train loss: 0.3979, Train acc: 0.8562 | Val loss: 1.0145, Val acc: 0.6936\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_Optimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, lr, device)\u001b[0m\n\u001b[0;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aaf6\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# On full set, it trains for really long time, reserve around 6 hours or reduce the size of the training set\n",
    "train_model(model_Optimal, train_loader_full, val_loader_full, num_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "579b1b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0459, Test Accuracy: 0.7019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0459329684178034, 0.7019111111111112)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluate(model_Optimal, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7c19941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at Models_Pytorch_saved/OptimalCNN_trained_saved.pth\n"
     ]
    }
   ],
   "source": [
    "# Saving model into the pytorch format\n",
    "save_model(model_Optimal, \"Models_Pytorch_saved/OptimalCNN_trained_saved.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31050ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from Models_Pytorch_saved/OptimalCNN_trained_saved.pth\n"
     ]
    }
   ],
   "source": [
    "# Now load it\n",
    "model_Optimal_loaded = load_model(\"Models_Pytorch_saved/OptimalCNN_trained_saved.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0459, Test Accuracy: 0.7019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0459329684178034, 0.7019111111111112)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if evaluated the same with the loaded model\n",
    "evaluate(model_Optimal_loaded, test_loader)\n",
    "# yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ab73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
