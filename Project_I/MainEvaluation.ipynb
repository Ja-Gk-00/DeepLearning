{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3090f1",
   "metadata": {},
   "source": [
    "# Training and Evaluation for CINIC10 using SimpleCNN and OptimalCNN\n",
    "\n",
    "This notebook loads the converted dataset, trains the SimpleCNN model, and performs evaluation and inference on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "id": "440dd3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:49:51.604450Z",
     "start_time": "2025-03-07T17:49:50.632863Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from DataObjects import DataLoader\n",
    "from Architectures.SimpleCNN import SimpleCNN\n",
    "from Architectures.OptimalCNN import OptimalCNN\n",
    "from Architectures.StochasticDepthCNN import StochasticDepthCNN\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from utils import save_model, load_model"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0945689d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:49:51.616137Z",
     "start_time": "2025-03-07T17:49:51.607285Z"
    }
   },
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                num_epochs: int = 10, lr: float = 0.001,\n",
    "                device: torch.device = None) -> None:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion: nn.Module = nn.CrossEntropyLoss()\n",
    "    optimizer: torch.optim.Optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss: float = 0.0\n",
    "        train_correct: int = 0\n",
    "        total_train: int = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels).item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = train_correct / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss: float = 0.0\n",
    "        val_correct: int = 0\n",
    "        total_val: int = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch.data.to(device)\n",
    "                labels = batch.labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels).item()\n",
    "                total_val += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = val_correct / total_val\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {avg_train_loss:.4f}, Train acc: {train_acc:.4f} | Val loss: {avg_val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "def infer(model: nn.Module, data_loader: DataLoader,\n",
    "          device: torch.device = None) -> list:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    predictions: list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             test_loader: Optional[DataLoader] = None,\n",
    "             device: Optional[torch.device] = None) -> Tuple[float, float]:\n",
    "\n",
    "    if test_loader is None:\n",
    "        test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "        test_loader = DataLoader(test_dir, batch_size=64, shuffle=True)\n",
    "        \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_correct += torch.sum(preds == labels).item()\n",
    "            total_test += labels.size(0)\n",
    "    \n",
    "    avg_test_loss = test_loss / total_test\n",
    "    test_acc = test_correct / total_test\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    return avg_test_loss, test_acc\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ee232775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:49:51.784984Z",
     "start_time": "2025-03-07T17:49:51.657916Z"
    }
   },
   "source": [
    "# Setup directories and DataLoaders\n",
    "train_dir = os.path.join(\"Data\", \"Data_converted\", \"train\")\n",
    "val_dir = os.path.join(\"Data\", \"Data_converted\", \"valid\")\n",
    "\n",
    "train_loader = DataLoader(train_dir, batch_size=64, shuffle=True, max_per_class=150)\n",
    "val_loader = DataLoader(val_dir, batch_size=64, shuffle=False, max_per_class=150) \n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN(num_classes=10)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b96dd00a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:49:57.704736Z",
     "start_time": "2025-03-07T17:49:51.842374Z"
    }
   },
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 10.5128, Train acc: 0.1200 | Val loss: 2.2250, Val acc: 0.1593\n",
      "Epoch 2/10 - Train loss: 2.0804, Train acc: 0.2513 | Val loss: 2.0442, Val acc: 0.2760\n",
      "Epoch 3/10 - Train loss: 1.7536, Train acc: 0.3887 | Val loss: 2.0514, Val acc: 0.2940\n",
      "Epoch 4/10 - Train loss: 1.4589, Train acc: 0.5000 | Val loss: 1.9689, Val acc: 0.3480\n",
      "Epoch 5/10 - Train loss: 1.1925, Train acc: 0.5860 | Val loss: 2.1933, Val acc: 0.3540\n",
      "Epoch 6/10 - Train loss: 0.9969, Train acc: 0.6773 | Val loss: 2.3573, Val acc: 0.3353\n",
      "Epoch 7/10 - Train loss: 0.7333, Train acc: 0.7527 | Val loss: 2.3798, Val acc: 0.3520\n",
      "Epoch 8/10 - Train loss: 0.5155, Train acc: 0.8440 | Val loss: 2.6336, Val acc: 0.3580\n",
      "Epoch 9/10 - Train loss: 0.3605, Train acc: 0.8947 | Val loss: 2.7477, Val acc: 0.3447\n",
      "Epoch 10/10 - Train loss: 0.2417, Train acc: 0.9453 | Val loss: 3.0854, Val acc: 0.3607\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "189aca2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:50:11.579527Z",
     "start_time": "2025-03-07T17:49:57.710098Z"
    }
   },
   "source": [
    "test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "test_loader = DataLoader(test_dir, batch_size=64, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch.data.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = test_correct / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.9039, Test Accuracy: 0.2948\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "52e5fbd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:50:11.929638Z",
     "start_time": "2025-03-07T17:50:11.669770Z"
    }
   },
   "source": [
    "# Full training\n",
    "train_loader_full = DataLoader(train_dir, batch_size=64, shuffle=True)\n",
    "val_loader_full = DataLoader(val_dir, batch_size=64, shuffle=False) \n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = SimpleCNN(num_classes=10)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "159fc1d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:50:16.810Z",
     "start_time": "2025-03-07T17:50:11.945366Z"
    }
   },
   "source": [
    "# Train the model\n",
    "train_model(model_2, train_loader, val_loader, num_epochs=10, lr=0.001)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 7.2327, Train acc: 0.1047 | Val loss: 2.3028, Val acc: 0.1047\n",
      "Epoch 2/10 - Train loss: 2.2779, Train acc: 0.1460 | Val loss: 2.1953, Val acc: 0.1887\n",
      "Epoch 3/10 - Train loss: 2.0466, Train acc: 0.2713 | Val loss: 2.0523, Val acc: 0.2693\n",
      "Epoch 4/10 - Train loss: 1.8280, Train acc: 0.3633 | Val loss: 2.0300, Val acc: 0.2853\n",
      "Epoch 5/10 - Train loss: 1.5213, Train acc: 0.4660 | Val loss: 2.0767, Val acc: 0.3020\n",
      "Epoch 6/10 - Train loss: 1.2565, Train acc: 0.5640 | Val loss: 2.1524, Val acc: 0.3327\n",
      "Epoch 7/10 - Train loss: 1.0246, Train acc: 0.6607 | Val loss: 2.2738, Val acc: 0.3027\n",
      "Epoch 8/10 - Train loss: 0.7595, Train acc: 0.7633 | Val loss: 2.4209, Val acc: 0.3320\n",
      "Epoch 9/10 - Train loss: 0.5652, Train acc: 0.8220 | Val loss: 2.6935, Val acc: 0.3247\n",
      "Epoch 10/10 - Train loss: 0.4049, Train acc: 0.8827 | Val loss: 2.9802, Val acc: 0.3273\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "fb95a77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:50:30.515415Z",
     "start_time": "2025-03-07T17:50:16.824153Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_2.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch.data.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = test_correct / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.9039, Test Accuracy: 0.2948\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "a23077da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:50:30.565739Z",
     "start_time": "2025-03-07T17:50:30.528908Z"
    }
   },
   "source": [
    "## Different architecture\n",
    "model_Optimal = OptimalCNN(num_classes=10)\n",
    "model_Stochastic = StochasticDepthCNN(num_classes=10)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "154842b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T17:56:39.619931Z",
     "start_time": "2025-03-07T17:50:30.626361Z"
    }
   },
   "source": [
    "# Train the model\n",
    "# On full set, it trains for really long time, reserve around 6 hours or reduce the size of the training set\n",
    "train_model(model_Optimal, train_loader_full, val_loader_full, num_epochs=10, lr=0.001)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 1.3791, Train acc: 0.5009 | Val loss: 1.3286, Val acc: 0.5317\n",
      "Epoch 2/10 - Train loss: 1.0787, Train acc: 0.6152 | Val loss: 1.0358, Val acc: 0.6293\n",
      "Epoch 3/10 - Train loss: 0.9336, Train acc: 0.6678 | Val loss: 0.9514, Val acc: 0.6655\n",
      "Epoch 4/10 - Train loss: 0.8217, Train acc: 0.7082 | Val loss: 0.9101, Val acc: 0.6766\n",
      "Epoch 5/10 - Train loss: 0.7121, Train acc: 0.7475 | Val loss: 0.9434, Val acc: 0.6749\n",
      "Epoch 6/10 - Train loss: 0.6028, Train acc: 0.7840 | Val loss: 0.9007, Val acc: 0.6975\n",
      "Epoch 7/10 - Train loss: 0.4919, Train acc: 0.8260 | Val loss: 0.9196, Val acc: 0.6996\n",
      "Epoch 8/10 - Train loss: 0.3865, Train acc: 0.8625 | Val loss: 0.9845, Val acc: 0.6997\n",
      "Epoch 9/10 - Train loss: 0.3015, Train acc: 0.8927 | Val loss: 1.0719, Val acc: 0.7050\n",
      "Epoch 10/10 - Train loss: 0.2324, Train acc: 0.9170 | Val loss: 1.1728, Val acc: 0.7018\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:02:45.907680Z",
     "start_time": "2025-03-07T17:56:39.675983Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model_Stochastic, train_loader_full, val_loader_full, num_epochs=10, lr=0.001)",
   "id": "10256a4113de10ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 1.4494, Train acc: 0.4754 | Val loss: 1.2139, Val acc: 0.5651\n",
      "Epoch 2/10 - Train loss: 1.1357, Train acc: 0.5941 | Val loss: 1.0752, Val acc: 0.6161\n",
      "Epoch 3/10 - Train loss: 1.0104, Train acc: 0.6397 | Val loss: 0.9719, Val acc: 0.6545\n",
      "Epoch 4/10 - Train loss: 0.9092, Train acc: 0.6756 | Val loss: 0.9171, Val acc: 0.6757\n",
      "Epoch 5/10 - Train loss: 0.8152, Train acc: 0.7086 | Val loss: 0.9799, Val acc: 0.6655\n",
      "Epoch 6/10 - Train loss: 0.7283, Train acc: 0.7401 | Val loss: 0.8845, Val acc: 0.6925\n",
      "Epoch 7/10 - Train loss: 0.6407, Train acc: 0.7723 | Val loss: 0.8974, Val acc: 0.6940\n",
      "Epoch 8/10 - Train loss: 0.5581, Train acc: 0.8018 | Val loss: 0.8957, Val acc: 0.7019\n",
      "Epoch 9/10 - Train loss: 0.4701, Train acc: 0.8325 | Val loss: 0.9906, Val acc: 0.6877\n",
      "Epoch 10/10 - Train loss: 0.4028, Train acc: 0.8567 | Val loss: 1.0373, Val acc: 0.6853\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "579b1b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:03:01.065259Z",
     "start_time": "2025-03-07T18:02:45.966153Z"
    }
   },
   "source": [
    "# Evaluate\n",
    "evaluate(model_Optimal, test_loader)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2032, Test Accuracy: 0.6948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.2032027043369082, 0.6947666666666666)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:03:16.085348Z",
     "start_time": "2025-03-07T18:03:01.068640Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate(model_Stochastic, test_loader)",
   "id": "73b9e8b18aa0c024",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0504, Test Accuracy: 0.6836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.050440318025483, 0.6835777777777777)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "b7c19941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:03:16.155325Z",
     "start_time": "2025-03-07T18:03:16.129298Z"
    }
   },
   "source": [
    "# Saving model into the pytorch format\n",
    "save_model(model_Optimal, \"Models_Pytorch_saved/OptimalCNN_trained_saved.pth\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at Models_Pytorch_saved/OptimalCNN_trained_saved.pth\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "31050ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:03:16.192505Z",
     "start_time": "2025-03-07T18:03:16.181484Z"
    }
   },
   "source": [
    "# Now load it\n",
    "model_Optimal_loaded = load_model(\"Models_Pytorch_saved/OptimalCNN_trained_saved.pth\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from Models_Pytorch_saved/OptimalCNN_trained_saved.pth\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e2d2e838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:03:31.240911Z",
     "start_time": "2025-03-07T18:03:16.227328Z"
    }
   },
   "source": [
    "# Check if evaluated the same with the loaded model\n",
    "evaluate(model_Optimal_loaded, test_loader)\n",
    "# yes!"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2032, Test Accuracy: 0.6948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.2032027043369082, 0.6947666666666666)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "2e9ab73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T18:03:31.255854Z",
     "start_time": "2025-03-07T18:03:31.254399Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
