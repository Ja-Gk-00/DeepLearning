{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3090f1",
   "metadata": {},
   "source": [
    "# Training and Evaluation for CINIC10 using SimpleCNN\n",
    "\n",
    "This notebook loads the converted dataset, trains the SimpleCNN model, and performs evaluation and inference on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440dd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from DataObjects import DataLoader\n",
    "from Architectures.SimpleCNN import SimpleCNN\n",
    "from Architectures.OptimalCNN import OptimalCNN\n",
    "\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0945689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "                num_epochs: int = 10, lr: float = 0.001,\n",
    "                device: torch.device = None) -> None:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion: nn.Module = nn.CrossEntropyLoss()\n",
    "    optimizer: torch.optim.Optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss: float = 0.0\n",
    "        train_correct: int = 0\n",
    "        total_train: int = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels).item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = train_correct / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss: float = 0.0\n",
    "        val_correct: int = 0\n",
    "        total_val: int = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = batch.data.to(device)\n",
    "                labels = batch.labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels).item()\n",
    "                total_val += labels.size(0)\n",
    "        \n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_acc = val_correct / total_val\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {avg_train_loss:.4f}, Train acc: {train_acc:.4f} | Val loss: {avg_val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "def infer(model: nn.Module, data_loader: DataLoader,\n",
    "          device: torch.device = None) -> list:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    predictions: list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             test_loader: Optional[DataLoader] = None,\n",
    "             device: Optional[torch.device] = None) -> Tuple[float, float]:\n",
    "\n",
    "    if test_loader is None:\n",
    "        test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "        test_loader = DataLoader(test_dir, batch_size=64, shuffle=True)\n",
    "        \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    total_test = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs = batch.data.to(device)\n",
    "            labels = batch.labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_correct += torch.sum(preds == labels).item()\n",
    "            total_test += labels.size(0)\n",
    "    \n",
    "    avg_test_loss = test_loss / total_test\n",
    "    test_acc = test_correct / total_test\n",
    "    \n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    return avg_test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee232775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories and DataLoaders\n",
    "train_dir = os.path.join(\"Data\", \"Data_converted\", \"train\")\n",
    "val_dir = os.path.join(\"Data\", \"Data_converted\", \"valid\")\n",
    "\n",
    "train_loader = DataLoader(train_dir, batch_size=64, shuffle=True, max_per_class=150)\n",
    "val_loader = DataLoader(val_dir, batch_size=64, shuffle=False, max_per_class=150) \n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96dd00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 1.1707, Train acc: 0.5867 | Val loss: 2.4186, Val acc: 0.2927\n",
      "Epoch 2/10 - Train loss: 0.8279, Train acc: 0.7253 | Val loss: 2.6018, Val acc: 0.3093\n",
      "Epoch 3/10 - Train loss: 0.5913, Train acc: 0.8080 | Val loss: 3.0063, Val acc: 0.3160\n",
      "Epoch 4/10 - Train loss: 0.4302, Train acc: 0.8573 | Val loss: 3.2185, Val acc: 0.3240\n",
      "Epoch 5/10 - Train loss: 0.3442, Train acc: 0.8920 | Val loss: 3.5537, Val acc: 0.3320\n",
      "Epoch 6/10 - Train loss: 0.2194, Train acc: 0.9400 | Val loss: 3.8268, Val acc: 0.3293\n",
      "Epoch 7/10 - Train loss: 0.1430, Train acc: 0.9693 | Val loss: 4.4267, Val acc: 0.3273\n",
      "Epoch 8/10 - Train loss: 0.1244, Train acc: 0.9687 | Val loss: 4.5080, Val acc: 0.3320\n",
      "Epoch 9/10 - Train loss: 0.1471, Train acc: 0.9607 | Val loss: 4.5738, Val acc: 0.3327\n",
      "Epoch 10/10 - Train loss: 0.2647, Train acc: 0.9227 | Val loss: 4.4066, Val acc: 0.3353\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189aca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.6793, Test Accuracy: 0.2764\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "test_loader = DataLoader(test_dir, batch_size=64, shuffle=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch.data.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = test_correct / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e5fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training\n",
    "train_loader_full = DataLoader(train_dir, batch_size=64, shuffle=True)\n",
    "val_loader_full = DataLoader(val_dir, batch_size=64, shuffle=False) \n",
    "\n",
    "# Instantiate the model\n",
    "model_2 = SimpleCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159fc1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train loss: 0.4291, Train acc: 0.8567 | Val loss: 3.3108, Val acc: 0.3347\n",
      "Epoch 2/10 - Train loss: 0.2400, Train acc: 0.9373 | Val loss: 3.4594, Val acc: 0.3313\n",
      "Epoch 3/10 - Train loss: 0.1584, Train acc: 0.9600 | Val loss: 3.8230, Val acc: 0.3373\n",
      "Epoch 4/10 - Train loss: 0.1177, Train acc: 0.9707 | Val loss: 4.3002, Val acc: 0.3387\n",
      "Epoch 5/10 - Train loss: 0.0707, Train acc: 0.9880 | Val loss: 4.4719, Val acc: 0.3520\n",
      "Epoch 6/10 - Train loss: 0.0504, Train acc: 0.9920 | Val loss: 4.7958, Val acc: 0.3433\n",
      "Epoch 7/10 - Train loss: 0.0460, Train acc: 0.9900 | Val loss: 5.1337, Val acc: 0.3320\n",
      "Epoch 8/10 - Train loss: 0.0937, Train acc: 0.9740 | Val loss: 5.1910, Val acc: 0.3100\n",
      "Epoch 9/10 - Train loss: 0.1296, Train acc: 0.9627 | Val loss: 5.4133, Val acc: 0.3193\n",
      "Epoch 10/10 - Train loss: 0.1153, Train acc: 0.9673 | Val loss: 5.2266, Val acc: 0.3307\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model_2, train_loader, val_loader, num_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb95a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.6793, Test Accuracy: 0.2764\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_2.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch.data.to(device)\n",
    "        labels = batch.labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += torch.sum(preds == labels).item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "test_acc = test_correct / total_test\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a23077da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different architecture\n",
    "model_Optimal = OptimalCNN(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154842b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model_Optimal, train_loader_full, val_loader_full, num_epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate(model_Optimal, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
