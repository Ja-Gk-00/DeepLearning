{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Evaluation Notebook\n",
    "In the following notebook, we will take a look for the evaluation of the ensemble models for two different kinds of ensemble:\n",
    "- stacking ensemble  \n",
    "- hard voting ensemble  \n",
    "\n",
    "The efficiency of the ensemble strategy will be evaluated, documented and compared to the standard methods.  \n",
    "The available code in the notebook will run the entire scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "\n",
    "from EnsembleModels.Ensemble import StackingEnsemble, HardVotingEnsemble, SoftVotingEnsemble\n",
    "from DataObjects import DataLoader\n",
    "from torch import Tensor\n",
    "from typing import Dict\n",
    "\n",
    "from Architectures.SimpleCNN import SimpleCNN\n",
    "from Architectures.OptimalCNN import OptimalCNN\n",
    "from Architectures.StochasticDepthCNN import StochasticDepthCNN\n",
    "\n",
    "from utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "\n",
    "num_classes: int = 10\n",
    "\n",
    "train_loader_path = os.path.join(\"Data\", \"Data_converted\", \"train\")\n",
    "val_loader_path = os.path.join(\"Data\", \"Data_converted\", \"valid\")\n",
    "test_loader_path = os.path.join(\"Data\", \"Data_converted\", \"test\")\n",
    "\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(train_loader_path, batch_size=64, shuffle=True, max_per_class=150)\n",
    "val_loader = DataLoader(val_loader_path, batch_size=64, shuffle=False, max_per_class=150) \n",
    "test_loader = DataLoader(test_loader_path, batch_size=64, shuffle=False, max_per_class=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from Models_Pytorch_saved\\OptimalCNN_trained_saved.pth\n",
      "Model loaded successfully from Models_Pytorch_saved\\OptimalCNN_trained_saved.pth\n",
      "Model loaded successfully from Models_Pytorch_saved\\OptimalCNN_trained_saved.pth\n"
     ]
    }
   ],
   "source": [
    "model_Optimal_1 = load_model(os.path.join(\"Models_Pytorch_saved\", \"OptimalCNN_trained_saved.pth\"))\n",
    "model_Optimal_2 = load_model(os.path.join(\"Models_Pytorch_saved\", \"OptimalCNN_trained_saved.pth\"))\n",
    "model_Optimal_3 = load_model(os.path.join(\"Models_Pytorch_saved\", \"OptimalCNN_trained_saved.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models: Dict[str, nn.Module] = {\"Model_Optimal_1\": model_Optimal_1, \"Model_Optimal_2\": model_Optimal_2, \"Model_Optimal_3\": model_Optimal_3}\n",
    "stacking_ensemble: StackingEnsemble = StackingEnsemble(base_models, num_classes)\n",
    "hard_voting_ensemble: HardVotingEnsemble = HardVotingEnsemble(base_models)\n",
    "soft_voting_ensemble: SoftVotingEnsemble = SoftVotingEnsemble(base_models)\n",
    "\n",
    "stacking_ensemble.to(device)\n",
    "optimizer = optim.Adam(stacking_ensemble.meta_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:06<02:03,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:18<02:52,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:29<02:57, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:40<02:50, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:51<02:39, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [01:02<02:29, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [01:13<02:22, 10.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:21<02:00, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:28<01:38,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:33<01:19,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:39<01:04,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:44<00:53,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:50<00:43,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:56<00:37,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [02:02<00:31,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:09<00:25,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:16<00:20,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:23<00:13,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:29<00:06,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:35<00:00,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Test Loss: 0.7572781588236491\n",
      "Stacking Ensemble Test Accuracy: 0.8233333333333334\n",
      "Hard Voting Ensemble Test Accuracy: 0.82\n",
      "Hard Voting Ensemble Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "stacking_ensemble.train_ensemble(train_loader, optimizer, criterion, device, epochs=20)\n",
    "loss, acc = stacking_ensemble.test(test_loader, criterion, device)\n",
    "print(\"Stacking Ensemble Test Loss:\", loss)\n",
    "print(\"Stacking Ensemble Test Accuracy:\", acc)\n",
    "\n",
    "hv_acc = hard_voting_ensemble.test(test_loader, device)\n",
    "print(\"Hard Voting Ensemble Test Accuracy:\", hv_acc)\n",
    "\n",
    "sv_acc = soft_voting_ensemble.test(test_loader, device)\n",
    "print(\"Soft Voting Ensemble Test Accuracy:\", sv_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
